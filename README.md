# CrewAI Agent MCP

Un agente inteligente de CrewAI que utiliza el protocolo MCP (Model Context Protocol) para realizar scraping web y extraer informaciÃ³n de portafolios de SoftwareOne Company.

## ğŸš€ CaracterÃ­sticas

- **Agente de Scraping Inteligente**: Utiliza CrewAI para crear un agente especializado en extracciÃ³n de informaciÃ³n web
- **Protocolo MCP**: IntegraciÃ³n con Model Context Protocol para herramientas avanzadas
- **LLM Configurable**: Soporte para mÃºltiples modelos de lenguaje (Gemini, OpenAI, Claude)
- **Scraping Dirigido**: Enfocado en extraer informaciÃ³n de portafolios especÃ­ficos de SoftwareOne

## ğŸ“‹ Requisitos Previos

- Python 3.13+
- UV (gestor de paquetes)
- API Key de Google Gemini (o el LLM de tu preferencia)
- Servidor MCP ejecutÃ¡ndose en `http://localhost:8000/mcp`

### ğŸ”— Servidor MCP Requerido

Este proyecto requiere el servidor MCP de CrewAI para funcionar correctamente. El servidor proporciona las herramientas de scraping web necesarias:

**Repositorio del Servidor MCP**: [crewai-mcp-server](https://github.com/OrlandContreras/crewai-mcp-server)

El servidor MCP integra herramientas de CrewAI para proporcionar capacidades de scraping web a travÃ©s del protocolo Model Context Protocol (MCP).

## ğŸ› ï¸ InstalaciÃ³n

1. **Clona el repositorio**:
   ```bash
   git clone <tu-repositorio>
   cd crewai-agent-mcp
   ```

2. **Instala las dependencias**:
   ```bash
   uv sync
   ```

3. **Configura el servidor MCP**:
   
   Clona e instala el servidor MCP requerido:
   ```bash
   # En otra terminal o directorio
   git clone https://github.com/OrlandContreras/crewai-mcp-server.git
   cd crewai-mcp-server
   uv sync
   python main.py
   ```
   
   El servidor debe estar ejecutÃ¡ndose en `http://localhost:8000/mcp` antes de ejecutar el agente.

4. **Configura las variables de entorno**:
   ```bash
   cp .env.example .env
   ```
   
   Edita el archivo `.env` y agrega tus API keys:
   ```env
   GOOGLE_API_KEY=tu_google_api_key_aqui
   MCP_SERVER_URL=http://localhost:8000/mcp
   ```

## ğŸš€ Uso

### EjecuciÃ³n BÃ¡sica

```bash
python main.py
```

### ConfiguraciÃ³n del Agente

El agente estÃ¡ configurado para:
- **Rol**: Scraper Agent
- **Objetivo**: Extraer informaciÃ³n de portafolios de SoftwareOne Company
- **Website objetivo**: `https://www.softwareone.com/es-co/{portfolio_type}`
- **Tipo de portafolio por defecto**: "Digital Workplace Services"

### PersonalizaciÃ³n

Puedes modificar el tipo de portafolio editando la variable en `main.py`:

```python
result = crew.kickoff(
    inputs={
        "portfolio_type": "Cloud Services"  # Cambia aquÃ­
    }
)
```

## ğŸ“ Estructura del Proyecto

```
crewai-agent-mcp/
â”œâ”€â”€ main.py              # Archivo principal del agente
â”œâ”€â”€ pyproject.toml        # ConfiguraciÃ³n del proyecto y dependencias
â”œâ”€â”€ .env.example          # Plantilla de variables de entorno
â”œâ”€â”€ .gitignore           # Archivos ignorados por Git
â”œâ”€â”€ README.md            # Este archivo
â””â”€â”€ uv.lock              # Lockfile de dependencias
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno Disponibles

| Variable | DescripciÃ³n | Valor por Defecto |
|----------|-------------|-------------------|
| `GOOGLE_API_KEY` | API Key de Google Gemini | Requerido |


### Modelos LLM Soportados

- **Google Gemini**: `gemini/gemini-2.0-flash`

## ğŸ—ï¸ Arquitectura del Sistema

Este proyecto utiliza una arquitectura de dos componentes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CrewAI Agent      â”‚  MCP  â”‚   MCP Server        â”‚
â”‚   (main.py)         â”‚<----->â”‚   (crewai-mcp-server)â”‚
â”‚                     â”‚       â”‚                     â”‚
â”‚ - Gemini LLM        â”‚       â”‚ - Scraping Tools    â”‚
â”‚ - Task Execution    â”‚       â”‚ - Web Content Fetch â”‚
â”‚ - Result Processing â”‚       â”‚ - HTTP API          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Componentes

- **Agent CrewAI**: Orquesta las tareas de scraping usando inteligencia artificial
- **Servidor MCP**: Proporciona las herramientas de scraping web a travÃ©s del protocolo MCP
- **Protocolo MCP**: Facilita la comunicaciÃ³n entre el agente y las herramientas de scraping

## ğŸ¤– Funcionamiento del Agente

1. **InicializaciÃ³n**: El agente se conecta al servidor MCP para obtener herramientas de scraping
2. **ConfiguraciÃ³n**: Se establece el LLM (Gemini por defecto) y los parÃ¡metros
3. **CreaciÃ³n de Tarea**: Se define la tarea de scraping con el tipo de portafolio especÃ­fico
4. **EjecuciÃ³n**: El crew ejecuta la tarea de forma secuencial
5. **Resultado**: Se retorna la informaciÃ³n extraÃ­da del portafolio

## ğŸ“Š Salida Esperada

El agente extraerÃ¡ informaciÃ³n estructurada sobre los servicios del portafolio, incluyendo:
- Servicios en la nube
- TransformaciÃ³n digital
- Ciberseguridad
- Servicios de TI

## ğŸ› ï¸ Desarrollo

### Dependencias Principales

- `crewai`: Framework para agentes AI colaborativos
- `crewai-tools[mcp]`: Herramientas MCP para CrewAI

### Ejecutar en Modo Desarrollo

```bash
# Activar el entorno virtual
source .venv/bin/activate

# Ejecutar con logs detallados
CREWAI_VERBOSE=true python main.py
```

## ğŸ› ResoluciÃ³n de Problemas

### Error: "Import crewai could not be resolved"
```bash
uv sync
```

### Error: "MCP Server not available"
- Verificar que el servidor MCP estÃ© ejecutÃ¡ndose en `http://localhost:8000/mcp`
- Comprobar la configuraciÃ³n en `MCP_SERVER_URL`
- Asegurarse de que el servidor [crewai-mcp-server](https://github.com/OrlandContreras/crewai-mcp-server) estÃ© clonado e iniciado
- Verificar que no haya conflictos de puertos en el sistema

### Error: "API Key not found"
- Verificar que `.env` existe y contiene `GOOGLE_API_KEY`
- Comprobar que la API key es vÃ¡lida

